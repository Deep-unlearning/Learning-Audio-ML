# My Journey into Learning Audio ML

## About

This repository documents my journey into learning Audio ML, bridging the gap in my knowledge as I transition from a more general deep learning background. The exploration is not strictly linear and may branch into broader deep learning topics. It serves as a space for experimentation, implementation of research papers, writing blog posts, and creating tutorials on related subjects.

## What am I currently working on

- ASR:

  - [Fast-Conformer](https://github.com/Deep-unlearning/fast-conformer): Implementing Fast-Conformer paper (https://arxiv.org/pdf/2305.05084) and probably other variants and optimizations.
 
  - [WIP] Study [Slam](https://github.com/slp-rl/slamkit)
  
  - [WIP] Blog post about Audio LMs
  
  - [WIP] Blog post about distil-whisper + tutorial
 
- TTS:

  - Finetuning Llasa: [Blog Post](https://huggingface.co/blog/Steveeeeeeen/llasagna) [Repo](https://github.com/Deep-unlearning/LLaSA_training)
  
## Useful Ressources

- List of [Awesome AudioLM Datasets](https://github.com/yuekaizhang/Awesome-AudioLM-Datasets)

- Torchaudio tutorials: https://pytorch.org/audio/main/index.html

- WAVLab Lectures on Speech Recognition and Understanding: https://www.youtube.com/@wavlab3016/videos

- Training recipe for Speech LMs: https://github.com/slp-rl/slamkit

- Conversational AI Reading Group: https://poonehmousavi.github.io/rg
